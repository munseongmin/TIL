# 2023.09.27 과제
## 1번 문제
- 크롤링: 네이버 지식인(키워드 지정), 영화 댓글(다음은 막혀 있음), 키워드 뉴스 기사
- 형태소 분리(Okt 형태소 분석기)
- 명사 / 형용사 추출 (okt.pos()함수 사용) - 참조 https://konlpy.org/ko/latest/api/konlpy.tag/#okt-class
- Korean POS tags comparison chart 에서는 이전 이름인 twitter로 찾아야 함. (품사 명 찾기)
- 시각화(워드클라우드, 바차트 .... )
```python
from bs4 import BeautifulSoup
from selenium import webdriver
import konlpy
import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
from selenium.webdriver.common.keys import Keys
import time

#영화 소공녀 댓글 보기
browser=webdriver.Chrome()
url='https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EC%98%81%ED%99%94+%EC%86%8C%EA%B3%B5%EB%85%80+%ED%8F%89%EC%A0%90&oquery=%EC%98%81%ED%99%94+%EC%9E%A0+%ED%8F%89%EC%A0%90&tqi=ie58FdprvhGss58GjkGssssssnh-399680'
browser.get(url)

#스포일러 포함 클릭하여 모든 댓글 보기
spoiler_btn='#main_pack > div.sc_new.cs_common_module.case_empasis.color_2._au_movie_content_wrap > div.cm_content_wrap > div.cm_content_area._cm_content_area_rating > div > div:nth-child(2) > div.cm_tap_area.type_48.type_white._sorting_wrap > div > div.lego_toggle_sort._spoiler_switch > button > span.bg_wrap'
scroll_area=browser.find_element('css selector', spoiler_btn).click()

# 스크롤 내리기 코드
'''
scroll_area='#main_pack > div.sc_new.cs_common_module.case_empasis.color_2._au_movie_content_wrap > div.cm_content_wrap > div.cm_content_area._cm_content_area_rating > div > div:nth-child(2) > div.lego_review_list._scroller'
inner_scroll=browser.find_element('css selector',  scroll_area).location

#셀레니움 스크롤 끝까지 내려도 계속 내리는 페이지라면
prev_height = browser.execute_script("return document. body.scrollHeight", inner_scroll)
import time
while True:
#첫번째로 스크롤 내리기
    browser.execute_script("window.scrollTo(0,document.body.scrollHeight)", inner_scroll)

#시간대기
    time.sleep(2)

#현재높이 저장
    current_height = browser.execute_script("return document. body.scrollHeight", inner_scroll)

#현재높이와 끝의 높이가 끝이면 탈출
    if current_height == prev_height:
        break
#업데이트해줘서 끝낼 수 있도록
    prev_height == current_height
'''

html=browser.page_source
soup=BeautifulSoup(html, 'html.parser')
comments=soup.select('li.area_card._item')

#댓글 개수 확인
len(comments)

#댓글 추출하여 리스트로 저장
Microhabitat=[]
for comment in comments:
    commentary=comment.select('span.desc._text')[0].text.strip()
    Microhabitat.append(commentary)

#데이터 프레임으로 변환
df=pd.DataFrame(Microhabitat)
#텍스트 파일로 저장
df.to_csv('Microhabitat.txt', index=False)
#저장한 텍스트 파일 읽어오기
movie=open('Microhabitat.txt', encoding = 'UTF-8').read()
#한글 제외한 문자들 전부 공백 문자로 변경
movie=re.sub('[^가-힣]', " ", movie)
#Okt 형태소 분석기 호출
okt=konlpy.tag.Okt()
#okt.pos() 함수 사용하여 각 단어와 품사 추출
pos=okt.pos(movie)

#품사가 Noun(명사) 이거나 Adjective(형용사)인 단어들만 추출
word=[]
for i in range(len(pos)):
    tag=pos[i][1]
    if tag == 'Noun' or tag == 'Adjective':
        word.append(pos[i][0])

#데이터 프레임을 변환
df_word=pd.DataFrame({'word' : word})

#추출된 단어들과 해당 단어 반복된 횟수를 내림 차순으로 정렬
df_word=df_word.groupby('word', as_index=False).agg(n=('word','count')).sort_values('n', ascending=False)
#폰트 설정
font='C:\Windows\Fonts\HMFMPYUN.TTF'
#딕셔너리 구조로 변환
dic_word=df_word.set_index('word').to_dict()['n']
#워드 클라우드 만들기
import PIL
icon = PIL.Image.open('cloud.png')
img = PIL.Image.new('RGB', icon.size, (255, 255, 255))
img.paste(icon, icon)
img = np.array(img)
wc = WordCloud(random_state = 1234,         # 난수 고정
               font_path = font,            # 폰트 설정
               width = 400,                 # 가로 크기
               height = 400,                # 세로 크기
               background_color = 'white',  # 배경색
               mask = img,                  # mask 설정
               colormap = 'inferno')        # 컬러맵 설정

img_wordcloud = wc.generate_from_frequencies(dic_word)

# 워드 클라우드 출력하기
plt.figure(figsize = (10, 10))  # 가로, 세로 크기 설정
plt.axis('off')                 # 테두리 선 없애기
plt.imshow(img_wordcloud)       # 워드 클라우드 출력               
```
![워드클라우드](/assets/Microhabitat.png)