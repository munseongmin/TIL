# 2023.09.20 과제
## 1번 문제
- 인스타그램에서 웹 정보를 수집하여 excel로 저장하기
- 버튼 클릭 등을 이용하여 게시글 여러개에 대해서 수집해보기
- 키워드는 자유롭게!!!
- 추출 내용: 본문 내용, 좋아요, 태그, 작성일
```python
from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
import time
import re

driver=webdriver.Chrome()
driver.get('https://www.instagram.com/')

#id와 pw를 입력하는 부분 찾기
input_id=driver.find_elements('css selector', '#loginForm > div > div:nth-child(1) > div > label > input')[0]
input_pw=driver.find_elements('css selector', '#loginForm > div > div:nth-child(2) > div > label > input')[0]

#id와 pw를 입력하고 로그인
input_id.send_keys('인스타그램 ID')
input_pw.send_keys('인스타그램 PW')
input_pw.submit()

#타투 검색
word='타투'
url='https://www.instagram.com/explore/tags/'+ word
driver.get(url)

#첫번째 피드 클릭하기
tattoo=driver.find_elements('css selector', '#mount_0_0_rZ > div > div > div.x9f619.x1n2onr6.x1ja2u2z > div > div > div > div.x78zum5.xdt5ytf.x1t2pt76.x1n2onr6.x1ja2u2z.x10cihs4 > div.x9f619.xvbhtw8.x78zum5.x168nmei.x13lgxp2.x5pf9jr.xo71vjh.x1uhb9sk.x1plvlek.xryxfnj.x1c4vz4f.x2lah0s.x1q0g3np.xqjyukv.x1qjc9v5.x1oa3qoh.x1qughib > div.x1gryazu.xh8yej3.x10o80wk.x14k21rp.x17snn68.x6osk4m.x1porb0y > section > main > article > div > div > div > div:nth-child(1) > div:nth-child(1) > a > div._aagu > div._aagw')[0]
tattoo.click()

#while문 사용하여 여러개의 피드에서 정보 수집하기
insta=[]
while True:
    try:
        #페이지 소스에 접근하기
        html=driver.page_source
        soup=BeautifulSoup(html, 'html.parser')
        
        #피드 내용
        content=soup.select('body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe.x1qjc9v5.xjbqb8w.x1lcm9me.x1yr5g0i.xrt01vj.x10y3i5r.xr1yuqi.xkrivgy.x4ii5y1.x1gryazu.x15h9jz8.x47corl.xh8yej3.xir0mxb.x1juhsu6 > div > article > div > div._ae65 > div > div > div._ae2s._ae3v._ae3w > div._ae5q._akdn._ae5r._ae5s > ul > div > li > div > div > div._a9zr')[0].text.split('#')[0]

        #좋아요
        like=soup.select('body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe.x1qjc9v5.xjbqb8w.x1lcm9me.x1yr5g0i.xrt01vj.x10y3i5r.xr1yuqi.xkrivgy.x4ii5y1.x1gryazu.x15h9jz8.x47corl.xh8yej3.xir0mxb.x1juhsu6 > div > article > div > div._ae65 > div > div > div._ae2s._ae3v._ae3w > section._ae5m._ae5n._ae5o > div > div > span')[0].text

        #해시태그
        tags=soup.select('body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe.x1qjc9v5.xjbqb8w.x1lcm9me.x1yr5g0i.xrt01vj.x10y3i5r.xr1yuqi.xkrivgy.x4ii5y1.x1gryazu.x15h9jz8.x47corl.xh8yej3.xir0mxb.x1juhsu6 > div > article > div > div._ae65 > div > div > div._ae2s._ae3v._ae3w > div._ae5q._akdn._ae5r._ae5s > ul > div > li > div > div > div._a9zr')[0].text
        tag=re.findall('#[^\s]+', tags)

        #작성일
        update=soup.select('body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe.x1qjc9v5.xjbqb8w.x1lcm9me.x1yr5g0i.xrt01vj.x10y3i5r.xr1yuqi.xkrivgy.x4ii5y1.x1gryazu.x15h9jz8.x47corl.xh8yej3.xir0mxb.x1juhsu6 > div > article > div > div._ae65 > div > div > div._ae2s._ae3v._ae3w > div._ae5u._ae5v._ae5w > div > div > a > span > time')[0].text
        
        #insta라는 list에 추가하기
        insta.append([content,like,tag,update])
        
        #다음 피드로 넘어가기
        nf=driver.find_elements('css selector', 'body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div:nth-child(1) > div > div > div._aaqg._aaqh > button')[0]
        nf.click()
        
    except:
        break

#데이터프레임으로 만들어서 엑셀 파일로 저장
df=pd.DataFrame(insta, columns=['피드내용', '좋아요', '해시태그', '작성일'])
df.to_excel('타투.xlsx', index=False)
```
### 문제풀이 중 개선점
- 중간에 피드 내용이 없을 시 out of range 에러 발생함.
- 키워드 검색 할때마다 페이지 소스 바뀌어서 첫번째 피드 클릭이 안됨.

---

## 2번 문제
- titanic 데이터에서 'Age' 열의 나이를
유아, 청소년, 청년, 중년, 장년, 노년으로 카테고리화 (한글/영문 상관x)
- Cate_Age 열에 저장하기
```python


```