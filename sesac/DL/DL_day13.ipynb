{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNGDeaetkTHcSoICll0E4pM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pXvXzzlrmtCq"},"outputs":[],"source":["#클래스로 모델 구현"]},{"cell_type":"code","source":["'''\n","model = nn.Linear(1,1)\n","\n","상속\n","\n","붕어빵 기계(너비=10, 높이=5, 내용물=단팥, 굽는다(1분)... 부모 클래스 : 메서드, 속성, 내부 클래스 등)\n","agile 기법 : 허접하더라도 빠르게 만들고 계속 개선 -> 배포(time to market) release...\n","상속\n","\n","잉어빵 기계(자식 클래스)\n","\n","요구분석 설계 구현 테스트 배포 유지보수\n","\n","부모 클래스에서 상속받은 메서드 재정의 (overriding) 추상적 -> 구체적\n","'''"],"metadata":{"id":"gF8w4mAfnL0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"L1kfE0j6tqO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LinearRegressionModel(nn.Module): # Module 부모 클래스, LinearRegressionModel 자식 클래스\n","    def __init__(self): # LinearRegressionModel 클래스 객체가 생성될 때 자동 호출\n","        super().__init__() # 부모 클래스의 속성이 초기화\n","        self.linear=nn.Linear(1,1)\n","    def forward(self, x):\n","        return self.linear(x)"],"metadata":{"id":"-uMiS9PYnMZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LinearRegressionModel()"],"metadata":{"id":"s3PPXPL8nMi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])"],"metadata":{"id":"2eTDw7XUnMlt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LinearRegressionModel()"],"metadata":{"id":"iEbZBk5lnMod"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer=torch.optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"P-KFqD-ZnMrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 2000\n","for epoch in range(nb_epochs+1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","    # 비용 함수를 미분하여 gradient 계산\n","    cost.backward() # backward 연산\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","    # 100번마다 로그 출력\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"],"metadata":{"id":"WmX93VH0nMts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","미니배치 : 대규모 데이터를 작은 단위로 나누어 연산\n","\n","ex) 데이터 100 건\n","1 epoch : 100건의 데이터를 모두 학습\n","20 batch_size : 한 번에 20건의 데이터를 읽어서 학습(w, b 업데이트 -> 5 이터레이션, batch_size/전체 데이터수)\n","5 batch(mini) : 20 batch_size로 데이터를 5번 가져와서 학습 -> 100건 데이터 학습\n","이터레이션 : 1epoch에서 발생하는 w, b의 업데이트 횟수\n","\n","배치할 때마다 w, b에 대해 업데이트가 발생됨\n","\n","배치 학습 : 전체 데이터에 대해 한 번에 배치와 함께 업데이트\n","미니 배치 학습 : 전체 데이터에 대해 여러 번에 배치 및 업데이트 수행\n","\n","파이토치에서는 데이터셋(DataSet), 데이터로더(DataLoader)를 제공\n","-> 데이터 셔플, 미니 배치 학습, 병렬 처리 등의 연산을 빠르게 할 수 있음\n","'''"],"metadata":{"id":"AosLBHpQ3qDE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"],"metadata":{"id":"Vz177vkfnMxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultivariateLinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n","\n","    def forward(self, x):\n","        return self.linear(x)"],"metadata":{"id":"pvh880kYnM0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MultivariateLinearRegressionModel()"],"metadata":{"id":"nx4Jc1GNnM3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"],"metadata":{"id":"KVPgh9XZnM6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 2000\n","for epoch in range(nb_epochs+1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","    # model(x_train)은 model.forward(x_train)와 동일함.\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","    # 비용 함수를 미분하여 gradient 계산\n","    cost.backward()\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","    # 100번마다 로그 출력\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"],"metadata":{"id":"CsVOR8TUnM9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 로드"],"metadata":{"id":"m-MTRK8GnNA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset # 텐서데이터셋\n","from torch.utils.data import DataLoader # 데이터로더"],"metadata":{"id":"N0BnZ31YnNEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train  =  torch.FloatTensor([[73,  80,  75],\n","                               [93,  88,  93],\n","                               [89,  91,  90],\n","                               [96,  98,  100],\n","                               [73,  66,  70]])\n","y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"],"metadata":{"id":"8GJlHqUunNHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = TensorDataset(x_train, y_train)\n","# TensorDataset : 텐서 데이터를 전달받아 데이터셋(Dataset) 형태로 변환"],"metadata":{"id":"56N5ESaInNKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"81rsUyUxnNOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = nn.Linear(3,1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"],"metadata":{"id":"pdD_9bFYnNRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):\n","    # print(batch_idx)\n","    # print(samples)\n","    x_train, y_train = samples\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 계산\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","        ))"],"metadata":{"id":"Gw_8XV6hnNVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_var =  torch.FloatTensor([[73, 80, 75]])"],"metadata":{"id":"-pmkN3ANnNYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_y = model(new_var)"],"metadata":{"id":"iLORU7LznNb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_y"],"metadata":{"id":"Abtsf3LenNgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    # 데이터 전처리\n","  def __len__(self):\n","    # 데이터 개수\n","  def __getitem__(self, idx):\n","    # 데이터 1개를 리턴"],"metadata":{"id":"qxG77sDt-Sxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"gCC3jBEeUEp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","  def __init__(self):\n","    self.x_data = [[73, 80, 75],\n","                   [93, 88, 93],\n","                   [89, 91, 90],\n","                   [96, 98, 100],\n","                   [73, 66, 70]]\n","    self.y_data = [[152], [185], [180], [196], [142]]\n","\n","  # 총 데이터의 개수를 리턴\n","  def __len__(self):\n","    return len(self.x_data)\n","\n","  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n","  def __getitem__(self, idx):\n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x, y"],"metadata":{"id":"wwX1TyU6UmNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = CustomDataset()"],"metadata":{"id":"XT0eUt-LUo37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"CSyeabHaVFWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.nn.Linear(3,1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"],"metadata":{"id":"2Loij02kWOED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):\n","    # print(batch_idx)\n","    # print(samples)\n","    x_train, y_train = samples\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 계산\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","        ))"],"metadata":{"id":"vVpq8VVqWQbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"metadata":{"id":"bs1J__FkWYXT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["strategy = tf.distribute.TPUStrategy(resolver) # 분산 처리와 관련된 api"],"metadata":{"id":"4Ik1unjikSyb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model():\n","  return tf.keras.Sequential(\n","      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n","       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n","       tf.keras.layers.Flatten(),\n","       tf.keras.layers.Dense(256, activation='relu'),\n","       tf.keras.layers.Dense(128, activation='relu'),\n","       tf.keras.layers.Dense(10)])"],"metadata":{"id":"WSH55phpkbpj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope():\n","  model = create_model()\n","  model.compile(optimizer='adam',\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                metrics=['sparse_categorical_accuracy'])"],"metadata":{"id":"uFuBxtQil-Nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#BERT, TPU, 네이버 영화 댓글 분류기"],"metadata":{"id":"_RVdQZW8p9pO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"aVukSIeEmp0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","import pandas as pd\n","import numpy as np\n","import urllib.request\n","import os\n","from tqdm import tqdm\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertModel"],"metadata":{"id":"2UmME3XuqB11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"metadata":{"id":"T-zyOHZFqbED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"metadata":{"id":"TKhPYaVqqgr7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"],"metadata":{"id":"jSq-SnyZqnRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력"],"metadata":{"id":"JTPzfxIPqoQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data[:5]"],"metadata":{"id":"esIn6ZHnqpG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","train_data = train_data.reset_index(drop=True)\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"metadata":{"id":"0MwBcEiUq2Vi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_data)"],"metadata":{"id":"gkxTwReMrCqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = test_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","test_data = test_data.reset_index(drop=True)\n","print(test_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"metadata":{"id":"TzzAtQy7rLT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_data)"],"metadata":{"id":"4DTUulM6rND7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.drop_duplicates(subset=['document'], inplace=True)"],"metadata":{"id":"8n4rIbF-rSq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_data)"],"metadata":{"id":"Iv38PewMrc1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer=BertTokenizer.from_pretrained(\"klue/bert-base\")"],"metadata":{"id":"val8kpDZrfUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","BERT : 구글 104개 이상 국가의 언어로 만든 모델\n","\n","사전 학습된 한국어 BERT 모델\n","KorBERT : ETRI, 20gb이상 데이터, 3만개 이상의 단어\n","KoBERT, KoBART : SKT\n","\n","KoGPT2 : SKT\n","KoreALBERT : 40GB 이상 데이터\n","HyperCLOVA : 네이버, 초대규모 모델\n","KLUE-BERT\n","KoGPT : 카카오\n","'''"],"metadata":{"id":"kSrZQyubsAoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\")) #12개"],"metadata":{"id":"rUa10EZSvLqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\")) #14개 -> 2 : cls, 3 : spe"],"metadata":{"id":"YuO-39hOvMcr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokenizer.decode(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\")))"],"metadata":{"id":"PcnH0FY9wtUL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.pad_token_id"],"metadata":{"id":"3ZU-krtjxECT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_seq_len = 128"],"metadata":{"id":"8ahpxOmNxfrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_result = tokenizer.encode(\" 전율을         일으키는         영화 . 다시         보고싶은   영화 \"\n",", max_length=max_seq_len, pad_to_max_length=True)"],"metadata":{"id":"Akj4RPwGxwaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_result # 128 길이에 맞춰서 뒷부분 0으로 채움"],"metadata":{"id":"6c-legJ5yEjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#정수 인코딩, 세그먼트 인코딩, 어텐션 마스크"],"metadata":{"id":"2fyrbLoRyGyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 세그먼트 인코딩\n","[0]*max_seq_len"],"metadata":{"id":"EdGEl4tP2iN9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 어텐션 마스크 : 토큰 위치는 1, 패팅 위치는 0\n","tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\")"],"metadata":{"id":"6uhuVjHT2u77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_num = len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))\n","print(valid_num * [1] + (max_seq_len - valid_num) * [0])"],"metadata":{"id":"KAQJQxJe24-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n","#                                  댓글     긍/부      128\n","    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n","\n","    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n","        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n","        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n","\n","        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n","        padding_count = input_id.count(tokenizer.pad_token_id)\n","        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n","\n","        # token_type_id는 세그먼트 임베딩을 위한 것으로 이번 예제는 문장이 1개이므로 전부 0으로 통일.\n","        token_type_id = [0] * max_seq_len\n","\n","        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n","        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n","        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        data_labels.append(label)\n","\n","    input_ids = np.array(input_ids, dtype=int)\n","    attention_masks = np.array(attention_masks, dtype=int)\n","    token_type_ids = np.array(token_type_ids, dtype=int)\n","\n","    data_labels = np.asarray(data_labels, dtype=np.int32)\n","\n","    return (input_ids, attention_masks, token_type_ids), data_labels"],"metadata":{"id":"O8A-d6so26S6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data"],"metadata":{"id":"yEZFpgC33QOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X, train_y = convert_examples_to_features(train_data['document'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"],"metadata":{"id":"YdAaxMTR3cMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X"],"metadata":{"id":"HO734gHK5Mzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y"],"metadata":{"id":"ehQQytjr5mSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_X, test_y = convert_examples_to_features(test_data['document'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"],"metadata":{"id":"a-FIU9-25x2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X[0][0] # 첫번째 문장에 대한 input_id"],"metadata":{"id":"W_VQYFyH50V6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X[1][0] # 첫번째 문장에 대한 어텐션 마스크"],"metadata":{"id":"EXjDHN4s6HW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X[2][0] # 첫번째 문장에 대한 세그먼트"],"metadata":{"id":"R-kuUHrr6Qr8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(train_X[0][0])"],"metadata":{"id":"kVcGVZst6cRq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"3j8FYXA4QXRs"}},{"cell_type":"code","source":["# 최대 길이: 128\n","input_id = train_X[0][0]\n","attention_mask = train_X[1][0]\n","token_type_id = train_X[2][0]\n","label = train_y[0]\n","\n","print('단어에 대한 정수 인코딩 :',input_id)\n","print('어텐션 마스크 :',attention_mask)\n","print('세그먼트 인코딩 :',token_type_id)\n","print('각 인코딩의 길이 :', len(input_id))\n","print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n","print('레이블 :',label)"],"metadata":{"id":"EcF11GNB6pS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TFBertModel.from_pretrained(\"klue/bert-base\", from_pt=True)"],"metadata":{"id":"6S0Npp0u6yEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_seq_len = 128"],"metadata":{"id":"W9TTU1J_7UIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","attention_masks_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","token_type_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","\n","outputs = model([input_ids_layer, attention_masks_layer, token_type_ids_layer])"],"metadata":{"id":"BT03Y9L67arr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs[0])\n","#만들고자 하는 모델이 다:다 구조인 경우에는 outputs[0] 사용\n","#shape=(None, 128, 768), 입력 128 출력 128\n","#(배치크기, 문장길이, 단어벡터(토큰))\n","#768차원 벡터가 128개 있다"],"metadata":{"id":"eo-LPNNI7g0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs[1])\n","#만들고자 하는 모델이 다:1 구조인 경우에는 outputs[1] 사용\n","#shape=(None, 768), 입력 128 출력 1개\n","#(배치크기, 단어벡터(토큰))\n","#768차원 벡터가 1개 있다"],"metadata":{"id":"KhgUFvXl8ntr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bert 다:1 구조 모델 생성"],"metadata":{"id":"_iUSsmrW83E7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TFBertForSequenceClassification(tf.keras.Model):\n","    def __init__(self, model_name):\n","        super(TFBertForSequenceClassification, self).__init__()\n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n","        self.classifier = tf.keras.layers.Dense(1, # 종류 개수로 바뀔 수 있음\n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n","                                                activation='sigmoid', # softmax 으로 바뀔 수 있음\n","                                                name='classifier')\n","\n","    def call(self, inputs):\n","        input_ids, attention_mask, token_type_ids = inputs\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        cls_token = outputs[1] # outputs[0] 으로 바뀔 수 있음\n","        prediction = self.classifier(cls_token)\n","\n","        return prediction"],"metadata":{"id":"Du5ZpwJZ-KpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TPU 작동을 위한 코드 TPU 작동을 위한 코드\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"metadata":{"id":"-GoENYkX-W5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["strategy = tf.distribute.experimental.TPUStrategy(resolver)"],"metadata":{"id":"8qOUGcXI-mAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope():\n","  model = TFBertForSequenceClassification(\"klue/bert-base\")\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","  loss = tf.keras.losses.BinaryCrossentropy()\n","  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"],"metadata":{"id":"DTuMVGr4-oOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_X, train_y, epochs=2, batch_size=64, validation_split=0.2)"],"metadata":{"id":"Oxql1OZ1-xLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = model.evaluate(test_X, test_y, batch_size=1024)\n","print(\"test loss, test acc: \", results)"],"metadata":{"id":"zlTKA8ct_YVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sentiment_predict(new_sentence):\n","  input_id = tokenizer.encode(new_sentence, max_length=max_seq_len, pad_to_max_length=True)\n","\n","  padding_count = input_id.count(tokenizer.pad_token_id)\n","  attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n","  token_type_id = [0] * max_seq_len\n","\n","  input_ids = np.array([input_id])\n","  attention_masks = np.array([attention_mask])\n","  token_type_ids = np.array([token_type_id])\n","\n","  encoded_input = [input_ids, attention_masks, token_type_ids]\n","  score = model.predict(encoded_input)[0][0]\n","  print(score)\n","\n","  if(score > 0.5):\n","    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"],"metadata":{"id":"_yKlNdcaB6UM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_predict('내 친구 홍길동이가 이 영화를 보고 기겁을 하던데?')"],"metadata":{"id":"MLWN1mv7CCEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_predict('우리 엄마가 이 영화를 보셨는데, 끝날때까지 주무셨다고 합니다.')"],"metadata":{"id":"4r1PMwn9CJPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_predict('이것도 영화냐?')"],"metadata":{"id":"9la-1eDbCKoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8O6gXSapCSvD"},"execution_count":null,"outputs":[]}]}